<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML-Agents on SophBG</title>
    <link>http://localhost:1313/MasterVAR-HCI-blog/tags/ml-agents/</link>
    <description>Recent content in ML-Agents on SophBG</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Thu, 16 Oct 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/MasterVAR-HCI-blog/tags/ml-agents/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Training a Unity Agent using ML-Agents</title>
      <link>http://localhost:1313/MasterVAR-HCI-blog/posts/lab2/</link>
      <pubDate>Thu, 16 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/MasterVAR-HCI-blog/posts/lab2/</guid>
      <description>&lt;hr&gt;&#xA;&lt;h1 id=&#34;overview&#34;&gt;&#xA;  Overview&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#overview&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;In this project, I created a simple Unity game environment where a character must jump over incoming obstacles generated at random intervals.&#xA;The core mechanics are very similar to endless-runner games: the player can jump, obstacles move toward them, and the goal is to avoid collisions.&lt;/p&gt;&#xA;&lt;p&gt;For this version, the character is controlled entirely by reinforcement learning using &lt;strong&gt;Unity ML-Agents&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;ml-agent-setup&#34;&gt;&#xA;  ML-Agent Setup&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#ml-agent-setup&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;I used the &lt;strong&gt;PPO (Proximal Policy Optimization)&lt;/strong&gt; trainer with &lt;strong&gt;default ML-Agents hyperparameters&lt;/strong&gt;, except for the training duration.&lt;br&gt;&#xA;The model has currently been trained for: 87.130.390 epochs&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
